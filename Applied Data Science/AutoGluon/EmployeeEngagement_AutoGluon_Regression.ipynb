{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b74fca",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Overtime Prediction using AutoGluon (Regression)\n",
    "\n",
    "This notebook demonstrates how to use [AutoGluon](https://auto.gluon.ai) to predict **OvertimeHours** for employees based on other workplace factors such as salary, department, and performance.\n",
    "\n",
    "The goal is to use AutoML to train a regression model that estimates overtime workload, which could help in employee workload planning and HR decisions like:\n",
    "- Identify employees at risk of burnout or risk of overwork.\n",
    "- Support HR decisions and workforce planning and forecasting labor needs across departments.\n",
    "- Complement classification models that assess employee engagement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649b784",
   "metadata": {},
   "source": [
    "### ðŸ“š Data Dictionary\n",
    "\n",
    "| Feature           | Type        | Description                             |\n",
    "|-------------------|-------------|-----------------------------------------|\n",
    "| Gender            | Categorical | Employee's gender                       |\n",
    "| YearsWorked       | Numeric     | Number of years worked                  |\n",
    "| Department        | Categorical | Department name                         |\n",
    "| Country           | Categorical | Country of work                         |\n",
    "| MonthlySalary     | Numeric     | Monthly salary                          |\n",
    "| AnnualSalary      | Numeric     | Annual salary                           |\n",
    "| JobRate           | Numeric     | Job performance rating (1â€“5)            |\n",
    "| SickLeaves        | Numeric     | Number of sick leave days               |\n",
    "| UnpaidLeaves      | Numeric     | Number of unpaid leave days             |\n",
    "| Location_ID       | Numeric     | Encoded office location                 |\n",
    "| Department_ID     | Numeric     | Encoded department                      |\n",
    "| **OvertimeHours** | **Target**  | Total overtime hours (continuous value) |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ðŸ“¥ Load libraries",
   "id": "c5669c75d92286aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T22:49:44.313377Z",
     "start_time": "2025-04-14T22:49:39.534758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "#Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\19024\\DataScience\\Employees_clean.csv\")"
   ],
   "id": "96c5a215",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Drop target leakage and non-numeric identifiers\n",
    "\n",
    "- **Columns removed**:\n",
    "  - `'Performance_ID'`, `'Employee_ID'`, `'FirstName'`, `'LastName'`, and `'StartDate'` are dropped to avoid **target leakage** or because they are **non-numeric identifiers** with little predictive value.\n",
    "  - These columns could mislead the model or inflate performance if kept.\n",
    "\n",
    "- **Target variable**:\n",
    "  - `'OvertimeHours'` is selected as the **target** for prediction.\n",
    "  - This is a numeric variable, making the task a **regression problem**."
   ],
   "id": "617d2886527c1efe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T22:49:50.116705Z",
     "start_time": "2025-04-14T22:49:50.097331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_model = df.drop(['Performance_ID', 'Employee_ID', 'FirstName', 'LastName', 'StartDate'], axis=1)\n",
    "\n",
    "# Set up regression target\n",
    "target = 'OvertimeHours'"
   ],
   "id": "44a07863",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ðŸ§  Train AutoGluon regression model\n",
    "\n",
    "**AutoGluon's `TabularPredictor`** to automatically train multiple regression models.\n",
    "\n",
    "- **`problem_type='regression'`**: Tells AutoGluon that the target (`OvertimeHours`) is a continuous numeric value.\n",
    "\n",
    "- **`.fit(df_model)`**: Trains many models (e.g., LightGBM, XGBoost, neural networks) using the cleaned dataset.\n",
    "\n",
    "- **`predictor.leaderboard()`**:\n",
    "  - Displays all trained models ranked by performance (using RMSE).\n",
    "  - This helps identify the **best-performing model** for making predictions.\n"
   ],
   "id": "f0fdeff69c4c7b5"
  },
  {
   "cell_type": "code",
   "id": "e99c5678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T22:50:18.263985Z",
     "start_time": "2025-04-14T22:49:56.529367Z"
    }
   },
   "source": [
    "predictor = TabularPredictor(label=target, problem_type='regression').fit(df_model)\n",
    "\n",
    "#View leaderboard of trained models\n",
    "predictor.leaderboard()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250414_224956\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.94 GB / 11.78 GB (16.4%)\n",
      "Disk Space Avail:   43.84 GB / 237.36 GB (18.5%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"C:\\Users\\19024\\DataScience\\AutogluonModels\\ag-20250414_224956\"\n",
      "Train Data Rows:    689\n",
      "Train Data Columns: 11\n",
      "Label Column:       OvertimeHours\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1985.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.17 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['JobRate']\n",
      "\t\t('int', [])    : 7 | ['YearsWorked', 'Department_ID', 'Location_ID', 'MonthlySalary', 'AnnualSalary', ...]\n",
      "\t\t('object', []) : 3 | ['Gender', 'Department', 'Country']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 2 | ['Department', 'Country']\n",
      "\t\t('float', [])     : 1 | ['JobRate']\n",
      "\t\t('int', [])       : 7 | ['YearsWorked', 'Department_ID', 'Location_ID', 'MonthlySalary', 'AnnualSalary', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['Gender']\n",
      "\t0.1s = Fit runtime\n",
      "\t11 features in original data used to generate 11 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 551, Val Rows: 138\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-30.2149\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.27s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-32.0336\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-28.9509\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-28.9752\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-30.9736\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-28.9844\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-30.9778\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t-28.9043\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-28.9923\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\19024\\DataScience\\.venv\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-29.0292\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.826, 'KNeighborsUnif': 0.174}\n",
      "\t-28.8417\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21.6s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2361.7 rows/s (138 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"C:\\Users\\19024\\DataScience\\AutogluonModels\\ag-20250414_224956\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  model  score_val              eval_metric  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2 -28.841677  root_mean_squared_error       0.058432   \n",
       "1       NeuralNetFastAI -28.904347  root_mean_squared_error       0.024251   \n",
       "2            LightGBMXT -28.950909  root_mean_squared_error       0.008325   \n",
       "3              LightGBM -28.975198  root_mean_squared_error       0.004520   \n",
       "4              CatBoost -28.984411  root_mean_squared_error       0.008508   \n",
       "5               XGBoost -28.992312  root_mean_squared_error       0.006512   \n",
       "6         LightGBMLarge -29.029230  root_mean_squared_error       0.006588   \n",
       "7        KNeighborsUnif -30.214883  root_mean_squared_error       0.032169   \n",
       "8       RandomForestMSE -30.973644  root_mean_squared_error       0.050382   \n",
       "9         ExtraTreesMSE -30.977800  root_mean_squared_error       0.057063   \n",
       "10       KNeighborsDist -32.033585  root_mean_squared_error       0.020409   \n",
       "\n",
       "    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   7.790944                0.002012           0.035606            2   \n",
       "1   2.481977                0.024251           2.481977            1   \n",
       "2   1.138332                0.008325           1.138332            1   \n",
       "3   0.421193                0.004520           0.421193            1   \n",
       "4   8.150041                0.008508           8.150041            1   \n",
       "5   0.499730                0.006512           0.499730            1   \n",
       "6   0.863825                0.006588           0.863825            1   \n",
       "7   5.273360                0.032169           5.273360            1   \n",
       "8   0.969945                0.050382           0.969945            1   \n",
       "9   0.854576                0.057063           0.854576            1   \n",
       "10  0.009401                0.020409           0.009401            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         11  \n",
       "1        True          8  \n",
       "2        True          3  \n",
       "3        True          4  \n",
       "4        True          6  \n",
       "5        True          9  \n",
       "6        True         10  \n",
       "7        True          1  \n",
       "8        True          5  \n",
       "9        True          7  \n",
       "10       True          2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-28.841677</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>7.790944</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.035606</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-28.904347</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>2.481977</td>\n",
       "      <td>0.024251</td>\n",
       "      <td>2.481977</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-28.950909</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>1.138332</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>1.138332</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-28.975198</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.421193</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.421193</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-28.984411</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>8.150041</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>8.150041</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-28.992312</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.499730</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.499730</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-29.029230</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.863825</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>0.863825</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-30.214883</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>5.273360</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>5.273360</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-30.973644</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.050382</td>\n",
       "      <td>0.969945</td>\n",
       "      <td>0.050382</td>\n",
       "      <td>0.969945</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-30.977800</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.057063</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>0.057063</td>\n",
       "      <td>0.854576</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-32.033585</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.020409</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "0b862e71",
   "metadata": {},
   "source": [
    "## ðŸ“Š Summary of Regression Results\n",
    "\n",
    "AutoGluon automatically trained several models to predict `OvertimeHours` (a regression task). It evaluated model performance using **Root Mean Squared Error (RMSE)**, where **lower values indicate better predictions**.\n",
    "\n",
    "### ðŸ¥‡ Top Model:\n",
    "- **Model**: `WeightedEnsemble_L2`\n",
    "- **Validation RMSE**: **28.84**\n",
    "\n",
    "On average, the model's predicted number of **OvertimeHours** is about **+/- 28.84 hours away** from the actual value in the validation data.\n",
    "\n",
    "This ensemble model combined predictions from high-performing individual models, especially:\n",
    "- `NeuralNetFastAI`\n",
    "- `KNeighborsUnif`\n",
    "\n",
    "It outperformed all others based on validation score.\n",
    "\n",
    "### ðŸ“Œ Clarification: Regression vs. Classification (Cross-Notebook Comparison)\n",
    "\n",
    "This notebook used **regression** to predict the continuous variable `OvertimeHours`, which is a numeric field indicating how many extra hours an employee works.\n",
    "\n",
    "Previous notebooks in the [general project folder](https://github.com/w0435723/BIA_Repository/tree/main/Applied%20Data%20Science) that explores the Employees dataset, using **PyCaret** and **Scikit-learn** focused on **classification** models to predict the categorical variable `EngagementLevel` (e.g., `High`, `Medium`) for the Employees data set.\n",
    "\n",
    "### ðŸ”„ Why the Results Can't Be Directly Compared:\n",
    "- **Regression Metrics**: Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and RÂ² Score\n",
    "- **Classification Metrics**: Accuracy, Precision, Recall, F1-score, AUC\n",
    "\n",
    "These two model types serve **different predictive goals** and use **different evaluation methods**, so comparing RMSE to classification accuracy is not meaningful.\n",
    "\n",
    "### ðŸ”— View the Engagement Classification Notebook\n",
    "\n",
    " [Click here to view the Employee Engagement Classification Notebook (AutoGluon)]()\n",
    "\n",
    "### ðŸ’¡ Conclusion:\n",
    "\n",
    "While this regression model does not replace the engagement classification work, it **adds value** by offering a **numerical prediction** that can be analyzed alongside engagement insights.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
